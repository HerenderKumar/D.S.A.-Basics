//WHAT IS TIME COMPLEXITY?
/*Time complexity is a way to measure the efficiency of an algorithm in terms of how the execution time grows with the input size. 
In laymen language it helps us understand how long an algorithm might take to run as the amount of data increases.
Example: Time complexity is typically expressed using Big O notation (e.g., O(1), O(n), O(n²), etc.)*/
1. Constant time:O(1).
An algorithm has a time complexity of O(1) if its runtime does not depend on the input size. This means it takes the same amount of time to execute, regardless of the input.
Example: Accessing an element in an array by its index.
CODE:

int getElement(int arr[], int index) {
    return arr[index];
}

int main() {
    int arr[] = {1, 2, 3, 4, 5};
    int index = 2;
    cout << "Element at index " << index << " is: " <<


2.Linear Time:O(n).
An algorithm has a time complexity of O(n) if its runtime increases linearly with the input size. If you double the input size, the runtime also doubles.
Example: Finding the maximum element in an array.
CODE:
int findMax(int arr[], int n) {
    int maxVal = arr[0];
    for (int i = 1; i < n; i++) {
        if (arr[i] > maxVal) {
            maxVal = arr[i];
        }
    }
    return maxVal;
}

int main() {
    int arr[] = {1, 5, 3, 9, 2};
    int n = sizeof(arr) / sizeof(arr[0]);
    cout << "Maximum element is: " << findMax(arr, n) << endl;
    return 0;
}


3. Quadratic Time: O(n²)
An algorithm has a time complexity of O(n²) if the runtime grows as the square of the input size. This commonly occurs in algorithms that use nested loops.
Example: Printing all pairs of elements in an array.
CODE:
void printAllPairs(int arr[], int n) {
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            cout << "(" << arr[i] << ", " << arr[j] << ")" << endl;
        }
    }
}

int main() {
    int arr[] = {1, 2, 3};
    int n = sizeof(arr) / sizeof(arr[0]);
    printAllPairs(arr, n);
    return 0;
}


4. Logarithmic Time: O(log n)
An algorithm has a time complexity of O(log n) if the runtime grows logarithmically with the input size. These algorithms typically reduce the problem size by half in each step.

Example: Binary search on a sorted array.

CODE:
int binarySearch(int arr[], int n, int target) {
    int left = 0, right = n - 1;
    while (left <= right) {
        int mid = left + (right - left) / 2;
        if (arr[mid] == target) {
            return mid;
        } else if (arr[mid] < target) {
            left = mid + 1;
        } else {
            right = mid - 1;
        }
    }
    return -1;
}

int main() {
    int arr[] = {1, 3, 5, 7, 9};
    int n = sizeof(arr) / sizeof(arr[0]);
    int target = 5;
    int result = binarySearch(arr, n, target);
    if (result != -1) {
        cout << "Element found at index " << result << endl;
    } else {
        cout << "Element not found" << endl;
    }
    return 0;
}


5. Linearithmic Time: O(n log n)
Algorithms with time complexity O(n log n) are generally more efficient than O(n²) but less efficient than O(n). This complexity often occurs in efficient sorting algorithms.

Example: Merge Sort

CODE:

void merge(int arr[], int left, int mid, int right) {
    int n1 = mid - left + 1;
    int n2 = right - mid;

    int* L = new int[n1];
    int* R = new int[n2];

    for (int i = 0; i < n1; i++) L[i] = arr[left + i];
    for (int i = 0; i < n2; i++) R[i] = arr[mid + 1 + i];

    int i = 0, j = 0, k = left;
    while (i < n1 && j < n2) {
        if (L[i] <= R[j]) {
            arr[k++] = L[i++];
        } else {
            arr[k++] = R[j++];
        }
    }

    while (i < n1) arr[k++] = L[i++];
    while (j < n2) arr[k++] = R[j++];

    delete[] L;
    delete[] R;
}

void mergeSort(int arr[], int left, int right) {
    if (left >= right) return;
    int mid = left + (right - left) / 2;
    mergeSort(arr, left, mid);
    mergeSort(arr, mid + 1, right);
    merge(arr, left, mid, right);
}

int main() {
    int arr[] = {9, 7, 5, 3, 1};
    int n = sizeof(arr) / sizeof(arr[0]);
    mergeSort(arr, 0, n - 1);
    cout << "Sorted array: ";
    for (int i = 0; i < n; i++) cout << arr[i] << " ";
    cout << endl;
    return 0;
}



6. Exponential Time: O(2ⁿ)
An algorithm has a time complexity of O(2ⁿ) if the runtime doubles with each additional input element. These algorithms are very slow and impractical for large inputs.

Example: Calculating Fibonacci numbers with simple recursion.

CODE: 

int fibonacci(int n) {
    if (n <= 1) return n;
    return fibonacci(n - 1) + fibonacci(n - 2);
}

int main() {
    int n = 5;
    cout << "Fibonacci of " << n << " is: " << fibonacci(n) << endl;
    return 0;
}


